{"version":3,"file":"useSpeechRecognition.mjs","sources":["../../../../src/hooks/useSpeechRecognition/useSpeechRecognition.ts"],"sourcesContent":["import { useEffect, useState } from 'react';\n\n/** The use speech recognition hook options type */\ninterface UseSpeechRecognitionOptions {\n  /** If true, recognition continues even after pauses in speech. Default is false */\n  continuous?: SpeechRecognition['continuous'];\n  /** A list of grammar rules */\n  grammars?: SpeechRecognition['grammars'];\n  /** If true, interim (non-final) results are provided as the user speaks */\n  interimResults?: SpeechRecognition['interimResults'];\n  /** The language in which recognition should occur. Must be a valid BCP 47 language tag (e.g., \"en-US\", \"ru-RU\") */\n  language?: SpeechRecognition['lang'];\n  /** The maximum number of alternative transcripts returned for a given recognition result. Must be a positive integer */\n  maxAlternatives?: SpeechRecognition['maxAlternatives'];\n  /** Callback invoked when speech recognition ends */\n  onEnd?: () => void;\n  /** Callback invoked when an error occurs during recognition */\n  onError?: (error: SpeechRecognitionErrorEvent) => void;\n  /** Callback invoked when recognition produces a result */\n  onResult?: (event: SpeechRecognitionEvent) => void;\n  /** Callback invoked when speech recognition starts */\n  onStart?: () => void;\n}\n\n/** The return type of the useSpeechRecognition hook. */\ninterface UseSpeechRecognitionReturn {\n  /** The error state */\n  error: SpeechRecognitionErrorEvent | null;\n  /** The final transcript */\n  final: boolean;\n  /** Whether the hook is currently listening for speech */\n  listening: boolean;\n  /** The speech recognition instance */\n  recognition: SpeechRecognition;\n  /** Whether the current browser supports the Web Speech API */\n  supported: boolean;\n  /** The current transcript */\n  transcript: string;\n  /** Begins speech recognition */\n  start: () => void;\n  /** Ends speech recognition, finalizing results */\n  stop: () => void;\n  /** Toggles the listening state */\n  toggle: (value?: boolean) => void;\n}\n\nexport const getSpeechRecognition = () =>\n  window?.SpeechRecognition ?? window?.webkitSpeechRecognition;\n\n/**\n * @name useSpeechRecognition\n * @description - Hook that provides a streamlined interface for incorporating speech-to-text functionality\n * @category Browser\n *\n * @browserapi window.SpeechRecognition https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition\n *\n * @param {boolean} [options.continuous=false] Whether recognition should continue after pauses\n * @param {boolean} [options.interimResults=false] Whether interim results should be provided\n * @param {string} [options.language=\"en-US\"] The language for recognition, as a valid BCP 47 tag\n * @param {number} [options.maxAlternatives=1] The maximum number of alternative transcripts to return\n * @param {SpeechGrammarList} [options.grammars] A list of grammar rules\n * @param {() => void} [options.onStart] Callback invoked when speech recognition starts\n * @param {() => void} [options.onEnd] Callback invoked when speech recognition ends\n * @param {(error: SpeechRecognitionErrorEvent) => void} [options.onError] Callback invoked when an error occurs during recognition\n * @param {(event: SpeechRecognitionEvent) => void} [options.onResult] Callback invoked when recognition produces a result\n * @returns {UseSpeechRecognitionReturn} An object containing the speech recognition functionality\n *\n * @example\n * const { supported, value, recognition, listening, error, start, stop, toggle  } = useSpeechRecognition();\n */\nexport const useSpeechRecognition = (\n  options: UseSpeechRecognitionOptions = {}\n): UseSpeechRecognitionReturn => {\n  const supported = typeof window !== 'undefined' && !!getSpeechRecognition();\n\n  const {\n    continuous = false,\n    interimResults = false,\n    language = 'en-US',\n    grammars,\n    maxAlternatives = 1,\n    onStart,\n    onEnd,\n    onError,\n    onResult\n  } = options;\n\n  const [listening, setListening] = useState(false);\n  const [transcript, setTranscript] = useState('');\n  const [final, setFinal] = useState(false);\n  const [error, setError] = useState<SpeechRecognitionErrorEvent | null>(null);\n  const [recognition] = useState<SpeechRecognition>(() => {\n    if (!supported) return {} as SpeechRecognition;\n\n    const SpeechRecognition = getSpeechRecognition();\n    const speechRecognition = new SpeechRecognition();\n\n    speechRecognition.continuous = continuous;\n    if (grammars) speechRecognition.grammars = grammars;\n    speechRecognition.interimResults = interimResults;\n    speechRecognition.lang = language;\n    speechRecognition.maxAlternatives = maxAlternatives;\n\n    speechRecognition.onstart = () => {\n      setListening(true);\n      setFinal(false);\n      onStart?.();\n    };\n    speechRecognition.onend = () => {\n      setListening(false);\n      onEnd?.();\n    };\n    speechRecognition.onerror = (event) => {\n      setError(event);\n      setListening(false);\n      onError?.(event);\n    };\n    speechRecognition.onresult = (event) => {\n      console.log('onresult', event);\n      const currentResult = event.results[event.resultIndex];\n      const { transcript } = currentResult[0];\n\n      setTranscript(transcript);\n      setError(null);\n      onResult?.(event);\n    };\n    speechRecognition.onend = () => {\n      setListening(false);\n      speechRecognition.lang = language;\n    };\n\n    return speechRecognition;\n  });\n\n  useEffect(() => () => recognition.stop(), []);\n\n  const start = () => recognition.start();\n  const stop = () => recognition.stop();\n\n  const toggle = (value = !listening) => {\n    if (value) return start();\n    stop();\n  };\n\n  return {\n    supported,\n    transcript,\n    recognition,\n    final,\n    listening,\n    error,\n    start,\n    stop,\n    toggle\n  };\n};\n"],"names":["getSpeechRecognition","useSpeechRecognition","options","supported","continuous","interimResults","language","grammars","maxAlternatives","onStart","onEnd","onError","onResult","listening","setListening","useState","transcript","setTranscript","final","setFinal","error","setError","recognition","SpeechRecognition","speechRecognition","event","currentResult","useEffect","start","stop","value"],"mappings":";AA8CO,MAAMA,IAAuB,MAClC,QAAQ,qBAAqB,QAAQ,yBAuB1BC,IAAuB,CAClCC,IAAuC,OACR;AAC/B,QAAMC,IAAY,OAAO,SAAW,OAAe,CAAC,CAACH,EAAA,GAE/C;AAAA,IACJ,YAAAI,IAAa;AAAA,IACb,gBAAAC,IAAiB;AAAA,IACjB,UAAAC,IAAW;AAAA,IACX,UAAAC;AAAA,IACA,iBAAAC,IAAkB;AAAA,IAClB,SAAAC;AAAA,IACA,OAAAC;AAAA,IACA,SAAAC;AAAA,IACA,UAAAC;AAAA,EAAA,IACEV,GAEE,CAACW,GAAWC,CAAY,IAAIC,EAAS,EAAK,GAC1C,CAACC,GAAYC,CAAa,IAAIF,EAAS,EAAE,GACzC,CAACG,GAAOC,CAAQ,IAAIJ,EAAS,EAAK,GAClC,CAACK,GAAOC,CAAQ,IAAIN,EAA6C,IAAI,GACrE,CAACO,CAAW,IAAIP,EAA4B,MAAM;AACtD,QAAI,CAACZ,EAAW,QAAO,CAAA;AAEvB,UAAMoB,IAAoBvB,EAAA,GACpBwB,IAAoB,IAAID,EAAA;AAE9B,WAAAC,EAAkB,aAAapB,GAC3BG,QAA4B,WAAWA,IAC3CiB,EAAkB,iBAAiBnB,GACnCmB,EAAkB,OAAOlB,GACzBkB,EAAkB,kBAAkBhB,GAEpCgB,EAAkB,UAAU,MAAM;AAChC,MAAAV,EAAa,EAAI,GACjBK,EAAS,EAAK,GACdV,IAAA;AAAA,IAAU,GAEZe,EAAkB,QAAQ,MAAM;AAC9B,MAAAV,EAAa,EAAK,GAClBJ,IAAA;AAAA,IAAQ,GAEVc,EAAkB,UAAU,CAACC,MAAU;AACrC,MAAAJ,EAASI,CAAK,GACdX,EAAa,EAAK,GAClBH,IAAUc,CAAK;AAAA,IAAA,GAEjBD,EAAkB,WAAW,CAACC,MAAU;AACtC,cAAQ,IAAI,YAAYA,CAAK;AAC7B,YAAMC,IAAgBD,EAAM,QAAQA,EAAM,WAAW,GAC/C,EAAE,YAAAT,MAAeU,EAAc,CAAC;AAEtC,MAAAT,EAAcD,CAAU,GACxBK,EAAS,IAAI,GACbT,IAAWa,CAAK;AAAA,IAAA,GAElBD,EAAkB,QAAQ,MAAM;AAC9B,MAAAV,EAAa,EAAK,GAClBU,EAAkB,OAAOlB;AAAA,IAAA,GAGpBkB;AAAA,EAAA,CACR;AAED,EAAAG,EAAU,MAAM,MAAML,EAAY,KAAA,GAAQ,CAAA,CAAE;AAE5C,QAAMM,IAAQ,MAAMN,EAAY,MAAA,GAC1BO,IAAO,MAAMP,EAAY,KAAA;AAO/B,SAAO;AAAA,IACL,WAAAnB;AAAA,IACA,YAAAa;AAAA,IACA,aAAAM;AAAA,IACA,OAAAJ;AAAA,IACA,WAAAL;AAAA,IACA,OAAAO;AAAA,IACA,OAAAQ;AAAA,IACA,MAAAC;AAAA,IACA,QAda,CAACC,IAAQ,CAACjB,MAAc;AACrC,UAAIiB,UAAcF,EAAA;AAClB,MAAAC,EAAA;AAAA,IAAK;AAAA,EAYL;AAEJ;"}