{"version":3,"file":"useSpeechRecognition.cjs","sources":["../../../../src/hooks/useSpeechRecognition/useSpeechRecognition.ts"],"sourcesContent":["import { useEffect, useState } from 'react';\n\n/** The use speech recognition hook options type */\ninterface UseSpeechRecognitionOptions {\n  /** If true, recognition continues even after pauses in speech. Default is false */\n  continuous?: SpeechRecognition['continuous'];\n  /** A list of grammar rules */\n  grammars?: SpeechRecognition['grammars'];\n  /** If true, interim (non-final) results are provided as the user speaks */\n  interimResults?: SpeechRecognition['interimResults'];\n  /** The language in which recognition should occur. Must be a valid BCP 47 language tag (e.g., \"en-US\", \"ru-RU\") */\n  language?: SpeechRecognition['lang'];\n  /** The maximum number of alternative transcripts returned for a given recognition result. Must be a positive integer */\n  maxAlternatives?: SpeechRecognition['maxAlternatives'];\n  /** Callback invoked when speech recognition ends */\n  onEnd?: () => void;\n  /** Callback invoked when an error occurs during recognition */\n  onError?: (error: SpeechRecognitionErrorEvent) => void;\n  /** Callback invoked when recognition produces a result */\n  onResult?: (event: SpeechRecognitionEvent) => void;\n  /** Callback invoked when speech recognition starts */\n  onStart?: () => void;\n}\n\n/** The return type of the useSpeechRecognition hook. */\ninterface UseSpeechRecognitionReturn {\n  /** The error state */\n  error: SpeechRecognitionErrorEvent | null;\n  /** The final transcript */\n  final: boolean;\n  /** Whether the hook is currently listening for speech */\n  listening: boolean;\n  /** The speech recognition instance */\n  recognition: SpeechRecognition;\n  /** Whether the current browser supports the Web Speech API */\n  supported: boolean;\n  /** The current transcript */\n  transcript: string;\n  /** Begins speech recognition */\n  start: () => void;\n  /** Ends speech recognition, finalizing results */\n  stop: () => void;\n  /** Toggles the listening state */\n  toggle: (value?: boolean) => void;\n}\n\nexport const getSpeechRecognition = () =>\n  window?.SpeechRecognition ?? window?.webkitSpeechRecognition;\n\n/**\n * @name useSpeechRecognition\n * @description - Hook that provides a streamlined interface for incorporating speech-to-text functionality\n * @category Browser\n *\n * @browserapi window.SpeechRecognition https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition\n *\n * @param {boolean} [options.continuous=false] Whether recognition should continue after pauses\n * @param {boolean} [options.interimResults=false] Whether interim results should be provided\n * @param {string} [options.language=\"en-US\"] The language for recognition, as a valid BCP 47 tag\n * @param {number} [options.maxAlternatives=1] The maximum number of alternative transcripts to return\n * @param {SpeechGrammarList} [options.grammars] A list of grammar rules\n * @param {() => void} [options.onStart] Callback invoked when speech recognition starts\n * @param {() => void} [options.onEnd] Callback invoked when speech recognition ends\n * @param {(error: SpeechRecognitionErrorEvent) => void} [options.onError] Callback invoked when an error occurs during recognition\n * @param {(event: SpeechRecognitionEvent) => void} [options.onResult] Callback invoked when recognition produces a result\n * @returns {UseSpeechRecognitionReturn} An object containing the speech recognition functionality\n *\n * @example\n * const { supported, value, recognition, listening, error, start, stop, toggle  } = useSpeechRecognition();\n */\nexport const useSpeechRecognition = (\n  options: UseSpeechRecognitionOptions = {}\n): UseSpeechRecognitionReturn => {\n  const supported = typeof window !== 'undefined' && !!getSpeechRecognition();\n\n  const {\n    continuous = false,\n    interimResults = false,\n    language = 'en-US',\n    grammars,\n    maxAlternatives = 1,\n    onStart,\n    onEnd,\n    onError,\n    onResult\n  } = options;\n\n  const [listening, setListening] = useState(false);\n  const [transcript, setTranscript] = useState('');\n  const [final, setFinal] = useState(false);\n  const [error, setError] = useState<SpeechRecognitionErrorEvent | null>(null);\n  const [recognition] = useState<SpeechRecognition>(() => {\n    if (!supported) return {} as SpeechRecognition;\n\n    const SpeechRecognition = getSpeechRecognition();\n    const speechRecognition = new SpeechRecognition();\n\n    speechRecognition.continuous = continuous;\n    if (grammars) speechRecognition.grammars = grammars;\n    speechRecognition.interimResults = interimResults;\n    speechRecognition.lang = language;\n    speechRecognition.maxAlternatives = maxAlternatives;\n\n    speechRecognition.onstart = () => {\n      setListening(true);\n      setFinal(false);\n      onStart?.();\n    };\n    speechRecognition.onend = () => {\n      setListening(false);\n      onEnd?.();\n    };\n    speechRecognition.onerror = (event) => {\n      setError(event);\n      setListening(false);\n      onError?.(event);\n    };\n    speechRecognition.onresult = (event) => {\n      console.log('onresult', event);\n      const currentResult = event.results[event.resultIndex];\n      const { transcript } = currentResult[0];\n\n      setTranscript(transcript);\n      setError(null);\n      onResult?.(event);\n    };\n    speechRecognition.onend = () => {\n      setListening(false);\n      speechRecognition.lang = language;\n    };\n\n    return speechRecognition;\n  });\n\n  useEffect(() => () => recognition.stop(), []);\n\n  const start = () => recognition.start();\n  const stop = () => recognition.stop();\n\n  const toggle = (value = !listening) => {\n    if (value) return start();\n    stop();\n  };\n\n  return {\n    supported,\n    transcript,\n    recognition,\n    final,\n    listening,\n    error,\n    start,\n    stop,\n    toggle\n  };\n};\n"],"names":["getSpeechRecognition","useSpeechRecognition","options","supported","continuous","interimResults","language","grammars","maxAlternatives","onStart","onEnd","onError","onResult","listening","setListening","useState","transcript","setTranscript","final","setFinal","error","setError","recognition","SpeechRecognition","speechRecognition","event","currentResult","useEffect","start","stop","value"],"mappings":"yGA8CaA,EAAuB,IAClC,QAAQ,mBAAqB,QAAQ,wBAuB1BC,EAAuB,CAClCC,EAAuC,KACR,CAC/B,MAAMC,EAAY,OAAO,OAAW,KAAe,CAAC,CAACH,EAAA,EAE/C,CACJ,WAAAI,EAAa,GACb,eAAAC,EAAiB,GACjB,SAAAC,EAAW,QACX,SAAAC,EACA,gBAAAC,EAAkB,EAClB,QAAAC,EACA,MAAAC,EACA,QAAAC,EACA,SAAAC,CAAA,EACEV,EAEE,CAACW,EAAWC,CAAY,EAAIC,EAAAA,SAAS,EAAK,EAC1C,CAACC,EAAYC,CAAa,EAAIF,EAAAA,SAAS,EAAE,EACzC,CAACG,EAAOC,CAAQ,EAAIJ,EAAAA,SAAS,EAAK,EAClC,CAACK,EAAOC,CAAQ,EAAIN,EAAAA,SAA6C,IAAI,EACrE,CAACO,CAAW,EAAIP,EAAAA,SAA4B,IAAM,CACtD,GAAI,CAACZ,EAAW,MAAO,CAAA,EAEvB,MAAMoB,EAAoBvB,EAAA,EACpBwB,EAAoB,IAAID,EAE9B,OAAAC,EAAkB,WAAapB,EAC3BG,MAA4B,SAAWA,GAC3CiB,EAAkB,eAAiBnB,EACnCmB,EAAkB,KAAOlB,EACzBkB,EAAkB,gBAAkBhB,EAEpCgB,EAAkB,QAAU,IAAM,CAChCV,EAAa,EAAI,EACjBK,EAAS,EAAK,EACdV,IAAA,CAAU,EAEZe,EAAkB,MAAQ,IAAM,CAC9BV,EAAa,EAAK,EAClBJ,IAAA,CAAQ,EAEVc,EAAkB,QAAWC,GAAU,CACrCJ,EAASI,CAAK,EACdX,EAAa,EAAK,EAClBH,IAAUc,CAAK,CAAA,EAEjBD,EAAkB,SAAYC,GAAU,CACtC,QAAQ,IAAI,WAAYA,CAAK,EAC7B,MAAMC,EAAgBD,EAAM,QAAQA,EAAM,WAAW,EAC/C,CAAE,WAAAT,GAAeU,EAAc,CAAC,EAEtCT,EAAcD,CAAU,EACxBK,EAAS,IAAI,EACbT,IAAWa,CAAK,CAAA,EAElBD,EAAkB,MAAQ,IAAM,CAC9BV,EAAa,EAAK,EAClBU,EAAkB,KAAOlB,CAAA,EAGpBkB,CAAA,CACR,EAEDG,EAAAA,UAAU,IAAM,IAAML,EAAY,KAAA,EAAQ,CAAA,CAAE,EAE5C,MAAMM,EAAQ,IAAMN,EAAY,MAAA,EAC1BO,EAAO,IAAMP,EAAY,KAAA,EAO/B,MAAO,CACL,UAAAnB,EACA,WAAAa,EACA,YAAAM,EACA,MAAAJ,EACA,UAAAL,EACA,MAAAO,EACA,MAAAQ,EACA,KAAAC,EACA,OAda,CAACC,EAAQ,CAACjB,IAAc,CACrC,GAAIiB,SAAcF,EAAA,EAClBC,EAAA,CAAK,CAYL,CAEJ"}